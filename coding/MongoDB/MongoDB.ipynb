{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MongoDB\n",
    "### Intro\n",
    "In contrast to relational databases MongoDB is a document-oriented that has the following properties:\n",
    "- Works Faster (than relational databases)\n",
    "- Scalability (each document can be easily extended)\n",
    "- High Availability (data is stored on different nodes)\n",
    "- Cross - Platform ( Windows, Linux, Mac ...)\n",
    "\n",
    "The main concept is a **collection and a document.**\n",
    "\n",
    "### Collection\n",
    "Collection is a group of MongoDB documents (similar to a table in a relational database). However, a collection allows storing objects with different structure and properties.\n",
    "<br>\n",
    "<img src=\"img/mongo_structure.jpg\" alt=\"drawing\" width=\"500\"/>\n",
    "\n",
    "### Document\n",
    "It's similar to a row in a table in a relational database. A document can be considered as storage of keys and values. A key can be considered as a field name (e.g. ```'is_ordered': true```). Each document has an ```_id``` that is generated automatically. However, it can be defined by a user. \n",
    "\n",
    "Document is represented by a BSON (binary JSON). This type allows working with data types much faster (e.g. searching or processing). The main disadvantage of BSON is file size. However, it's compensated by the speed. \n",
    "\n",
    "MongoDB provides two types of data models: â€” Embedded data model and Normalized data model. Based on the requirement, you can use either of the models while preparing your document.\n",
    "<br>\n",
    "<img src=\"img/document_model.png\" alt=\"drawing\" width=\"500\"/>\n",
    "\n",
    "### Replicas\n",
    "Replication is data synchronization on different servers (machines). It helps to avoid failures and provide high availability. In MongoDb there are **replicaset servers**. In MongoDB exists two replication models:\n",
    "- **Master-Slave** (can be applied when we have more than 11 slaves)\n",
    "- **Replica Set** (in a single set can be only 12 members)\n",
    "\n",
    "A replica set is a group of mongod instances that host the same data set. In a replica, **one node is primary node** that receives all write operations. All other instances, such as **secondaries**, apply operations from the primary so that they have the same data set. Replica set can have only one primary node.\n",
    "<br>\n",
    "<img src=\"img/replica-mech.png\" alt=\"drawing\" width=\"500\"/>\n",
    "<br>\n",
    "At the time of automatic failover or maintenance, election establishes for primary and a new primary node is elected. After the recovery of failed node, it again join the replica set and works as a secondary node.\n",
    "\n",
    "In both models there is only **one node** that is responsible for **writing operations**. The rest nodes only read these operations and apply on itself. The main idea of replication to provide a data reservation.\n",
    "\n",
    "Replicas reservation and data back-up are different:\n",
    "- **Data Back-Up** - is a snapshot at some time\n",
    "- **Replica** - is always up-to-date\n",
    "\n",
    "Replica Set is based on two mechanisms:\n",
    "- **OpLog** - makes replication possible (i.e. is a journal where all changes are stored\n",
    "- **Heartbeat** - monitors the condition of the nodes and activates a procedure of a failure processing\n",
    "\n",
    "Each member of a replica set sends hearbeats to other members (every 2 seconds). Replicas allow scaling readability by changing read load among the nodes.\n",
    "\n",
    "### Sharding\n",
    "Sharding is the process of storing data records across multiple machines and it is MongoDB's approach to meeting the demands of data growth. As the size of the data increases, a single machine may not be sufficient to store the data nor provide an acceptable read and write throughput. Sharding solves the problem with horizontal scaling. With sharding, you add more machines to support data growth and the demands of read and write operations.\n",
    "\n",
    "**Why To Use Sharding**\n",
    "1. In replication, all writes go to master node\n",
    "2. Latency sensitive queries still go to master\n",
    "3. Single replica set has limitation of 12 nodes\n",
    "4. Memory can't be large enough when active dataset is big\n",
    "5. Local disk is not big enough\n",
    "6. Vertical scaling is too expensive\n",
    "\n",
    "More Info: https://www.tutorialspoint.com/mongodb/mongodb_sharding.htm\n",
    "\n",
    "### GridFS\n",
    "The main problem of any database is storing data with large size. For example, SQL provides a special type called BLOB. MongoDB allows storing different objects but the document size is limited to 16 Mb. A special technology called **GridFS** allows storing data more than 16 Mb.\n",
    "\n",
    "It allows storing and retrieving large files such as images, audio files, video files, etc. It is kind of a **file system** to store files but its data is stored within MongoDB collections. GridFS divides a file into chunks and stores each chunk of data in a separate document, each of maximum size 256 Kb. For example, a mp3 file can be divided into 40 documents (40 chunks of data)\n",
    "\n",
    "GridFS consists of two main collections:\n",
    "- **Files** - stores file names and metadata (e.g. file size)\n",
    "- **Chunks** - stores file segments. Each segment has a size of 256 Kb\n",
    "\n",
    "### Cursors\n",
    "Each result returned by ```find()``` is a **cursor.** A cursor allows making data processing on returning objects.\n",
    "\n",
    "A cursor can be created using: ```var cursor = db.col_name.find()```\n",
    "\n",
    "### Aggregation\n",
    "Distinguish the following types aggregation:\n",
    "- **Pipeline** ( preferable method)\n",
    "- **Map Reduce**\n",
    "- **Single Purpose**\n",
    "<br>\n",
    "<img src=\"img/aggreagation.png\" alt=\"drawing\" width=\"500\"/>\n",
    "<br>\n",
    "\n",
    "**Pipeline**\n",
    "\n",
    "A document goes through a multistage conveyor which then process the data into an aggregated result. There are filters and functions for grouping and sorting by a single or many fields or arrays aggregation. The main command:\n",
    "\n",
    "- ```db.collection.aggregate(pipeline, options)``` - the main command for a conveyor aggregation\n",
    "\n",
    "The following operators may be included into ```pipeline:```\n",
    "- ```{$match: {key:value}}``` - provides filtration by using a certain condition\n",
    "\n",
    "- ```{$group: {key: {$agg_funct: value}}}``` - provides grouping and applies $agg_funct\n",
    "\n",
    "- ```{$sort: {key: 1 or -1}}``` - sorts the result\n",
    "\n",
    "- ```{$project: {key: 1 or 0, key: 1 or 0 ...}}``` - selects those fields that we need\n",
    "\n",
    "- ```{$out: {'collection_name'}}``` - saves an aggregation result into a new collection (must be the last)\n",
    "\n",
    "- ```{$unwind: {$field_name}}``` - each array element becomes a new document\n",
    "\n",
    "- ```{$limit: value}``` - limits the final output\n",
    "\n",
    "- ```{$addfield: {key: value}}``` - adds a new filed in the result \n",
    "\n",
    "- ```{$count: 'name'}``` - counts the number of documents\n",
    "\n",
    "- ```{$lookup: {from: 'collection_to_join', localField: name, foreignField: name, as: name}``` - merges fields from two collections (fields that are going to be merged must have indexes for fast processing)\n",
    "\n",
    "\n",
    "- ```{$sortByCount : '$key'}``` - allows grouping, counting and then sorting in DESC order\n",
    "\n",
    "\n",
    "The following operators may be included into ```options:```\n",
    "- ```{allowDiskUse: true}``` - if not enough RAM, disk storage will be used\n",
    "\n",
    "**Examples**\n",
    "```\n",
    "db.authors.aggregate(\n",
    "  { $match: { spec: \"prog\" }},\n",
    "  { $project: { lvl: 1 } },\n",
    "  { $group: { _id: 'level', level: { $sum: '$lvl' } } },\n",
    "  { $sort: { lvl: 1 }}\n",
    ")\n",
    "```\n",
    "**Important**\n",
    "- ```$group``` - has a memory limitation. No more than 100 Mb. It can be solved using either ```allowDiskUse``` or ```$project``` to filter out unwanted fields\n",
    "\n",
    "**Map Reduce**\n",
    "\n",
    "This algorithm was introduced by Google for BigData processing. The concept is simple. There are two main functions:\n",
    "- ```map``` - maps fields according to conditions, drops and then groups them\n",
    "- ```reduce``` - rolls up values of grouped documents (makes aggregation)\n",
    "<br>\n",
    "<img src=\"img/map-reduce.png\" alt=\"drawing\" width=\"700\"/>\n",
    "<br>\n",
    "The main advantage of this algorithm is that we can make parallel computations allowing processing BigData much faster\n",
    "\n",
    "**Single Purpose Aggregation**\n",
    "\n",
    "It is a collection aggregation using a certain key (a field name)\n",
    "\n",
    "**Examples**\n",
    "- ```db.users.count()``` - counts all documents in a collection\n",
    "- ```db.products.distinct('name')``` - returns only unique names in a collection\n",
    "\n",
    "### MongoDB Schema\n",
    "A schema in a database determines the structure of a db. For example, in a relational database, we have to define a number of tables, primary and foreign keys. Type of relationships and so on. However, in MongoDB, there are no rules. But it doesn't mean that we should create a collection of unstructured documents. Instead, we have to determine the required fields, a number of collections and their structure.\n",
    "\n",
    "For instance, we can define a collection structure like that (it's called reference type)\n",
    "<img src=\"img/ref_type_col.png\" alt=\"drawing\" width=\"500\"/>\n",
    "<br>\n",
    "Or may be a **nested architecture** might be better\n",
    "<img src=\"img/embedded_col_type.png\" alt=\"drawing\" width=\"500\"/>\n",
    "<br>\n",
    "\n",
    "Is must be noticed that collections can be validated using validators (i.e. obligatory fields can be defined, document type...). It means that any new document will be checked and inserted only if it meets the requirements defined by a validator.\n",
    "\n",
    "### Document Links\n",
    "Collection can be linked using document fields. There are two ways:\n",
    "\n",
    "**Manual**\n",
    "\n",
    "Fields reference ids of other documents.\n",
    "\n",
    "```\n",
    "db.companies.insert({'_id': 'Apple', 'year': '1974'})\n",
    "db.users.insert({name: \"Tom\", age: 28, company: \"Apple\"})\n",
    "\n",
    "user = db.users.findOne()\n",
    "db.companies.findOne({_id: user.company})\n",
    "```\n",
    "\n",
    "**DBRef**\n",
    "\n",
    "DBRef makes automatic linking between documents. It has the following syntax\n",
    "```\n",
    "apple = ({'name': 'apple', 'year': 1976})\n",
    "db.companies.save(apple)\n",
    "\n",
    "steve = ({'name': 'Steve', 'age': 25, company: new DBRef('companies', apple._id)})\n",
    "db.users.save(steve)\n",
    "```\n",
    "\n",
    "```company``` in the collection users will contain (reference) ids of a company. Thus we can later easily find employees in Apple company.\n",
    "\n",
    "\n",
    "### Indexation\n",
    "Index is a **special data type** that stores a part of data collection in a form that is convenient for searching. Indexes allows ordering data by a field for fast searching. Without indexes, MongoDB has to look for a value by searching through the entire collection. \n",
    "\n",
    "Be default, ```_id``` is an index for any document. However, indexes can be different:\n",
    "\n",
    "**Single Index**\n",
    "\n",
    "Created only for a single field. For single index, the order isn't important.\n",
    "```db.users.createIndex({email:1})``` - creates a single index\n",
    "\n",
    "**Compound Index**\n",
    "\n",
    "Created for several fields. Order is important.\n",
    "```db.users.createIndex({city: 1, email: -1})``` - creates a compound index (frist city is sorted then email)\n",
    "\n",
    "**Multikey Index**\n",
    "\n",
    "Used for array elements indexing. An array usually consists of several elements, which then will be indexed and referenced to a single field. That's why it's called multikey.\n",
    "\n",
    "**Indexes Properties**\n",
    "\n",
    "- ```db.users.createIndex({email: 1}, {unique: true})``` - creates a unique index. email can't be indexed again\n",
    "\n",
    "**Sparse Indexes**\n",
    "\n",
    "Be default all indexes aren't sparsed (i.e. every document has an index). For example, some product may not be assigned to any category and will have ```null```. In this case, the sparse index is the case.\n",
    "- ```db.users.createIndex({email: 1}, {sparse: true})``` - creates a sparse index\n",
    "\n",
    "**TTL Indexes**\n",
    "\n",
    "Created for documents that must be dropped after some time (e.g. logs, session info, ...)\n",
    "- ```db.users.createIndex({email: 1}, {expireAfterSeconds: 120})``` - each document ordered by email will be dropped after 120 seconds\n",
    "\n",
    "Each index can be named\n",
    "- ```db.users.createIndex(  { email: 1 },  { name: 'catIdx' })```\n",
    "\n",
    "**Index Effectiveness**\n",
    "\n",
    "indexes allow increase data reading. However, operations such as data inserting will be slower (each document must be inserted in a collection and changed in a data structure). As a rule of thumb, drop indexes that aren't used.\n",
    "- ```db.collection.dropIndex(\"catIdx\")```\n",
    "\n",
    "To list all indexes\n",
    "- ```db.collection.getIndexes()```\n",
    "- ```db.collection.dropIndexes()```\n",
    "\n",
    "\n",
    "### Quieries Execution Time  \n",
    "- ```db.users.find({}).explain('allPlansExecution')``` - find out how much time is needed to execute a query\n",
    "- ```db.setProfilingLevel(1, time)``` - shows all queries that exceed provided time\n",
    "\n",
    "### NoSQL Types\n",
    "<img src=\"img/sql_no_sql.png\" alt=\"drawing\" width=\"700\"/>\n",
    "<br>\n",
    "\n",
    "**Important**\n",
    "-  If a **collection doesn't exist**, MongoDB creates the collection when you first store data for that collection\n",
    "- Collection is a JavaScript Object (BSON)\n",
    "- An ```_id``` is not obligatory. If not provided, it is created automatically by Mongo\n",
    "- If **access a field/variable from an array** or a field object (this field has {}), use 'field_name.variable'\n",
    "- Quotes are important\n",
    "- Every record in a Collection is called a **Document**\n",
    "- Documents are **elastic** (i.e. documents can have different structure what doesn't lead to any conflicts in a DB)\n",
    "- Queries are **case sensitive**\n",
    "- Mongo files have ```.js``` extension\n",
    "- By default documents are sorted and returned in the order in which they were added into a db\n",
    "- Several field names with the same name can't exist\n",
    "- Documents can be nested\n",
    "- To access embedded objects, use **the dot notation**\n",
    "- It is recommended to use ```skip()``` when skipping few elements (i.e. skipping more than 100 documents decreases performance)\n",
    "- If fields are going to be embedded, use ```field_name: {embedded elements}``` (documents update)\n",
    "- ```True``` can't be used, only ```true``` \n",
    "- Array elements and embedded objects can be accessed using the dot notation\n",
    "- To use ```count()``` with ```limit()``` and ```skip()``` use ```count(true)```\n",
    "- If an updating document doesn't have an updating field (using $set) it will be created $\n",
    "- MongoDB allows creating up to 64 indexes for a collection\n",
    "- Capped collection guarantees order of documents. Capped collections can be restricted (size and number of documents)\n",
    "- Order of $sort and $limit in the pipeline is important\n",
    "- If there are embedded arrays, then $unwind must be used twice\n",
    "- When referencing a field in an aggregate expression, you typically precede the field name with a dollar sign and enclose it in quotes.\n",
    "- The same data can be considered as atomic and not depending on a case (e.g. address) \n",
    "- if you rarely use your collection for read operations, it makes sense not to use indexes\n",
    "- ```db.collection.insert({})``` - allows inserting a single and multiple documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Commands\n",
    "- ```db``` - shows the current db name\n",
    "- ```use db_name``` - switches to a db\n",
    "- ```show collections``` - shows all collections\n",
    "- ```db.createCollection('collection_name')``` - creates a collection\n",
    "- ```db.stats()``` - returns the statistics about the current db\n",
    "- ```db.collection.stats()``` - returns the statistics about a collection\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Data Inserting \n",
    "There are several options how the data can be inserted:\n",
    "- ```db.collection.insertOne({record_1})``` - only inserts a single document \n",
    "- ```db.collection.insertMany([{record_1}, {record_2}, {record_n}])``` - allows inserting many documents\n",
    "- ```db.collection.insert({record or records})``` - combination of insertOne and insertMany\n",
    "- ```load(path)``` - imports the data from a file\n",
    "\n",
    "### Data Updating\n",
    "- ```db.collection.updateOne({data_filter}, {$set: {field_name: new_value}})``` - updates a document\n",
    "- ```db.collection.updateMany({data_filter}, {$set: {field_name: new_value}})``` - upddates several documents \n",
    "- ```db.collection.update({data_filter}, {$set: {field_name: new_value}})``` - similar to updateOne\n",
    "- ```db.collection.update({data_filter}, {$unset: {field_name: value}})``` - unsets/drops a field in a document\n",
    "- ```db.collection.update({data_fileter}, {$rename:{old_field_name: new_field_name}})``` - renames a field in a document\n",
    "\n",
    "**Important**\n",
    "- If ```$set``` isn't provided, the **entire document will be replaced** by a new value\n",
    "- Values can be incremented using ```{$inc: {age: 5}``` (e.g. ```$inc``` will increase age on 5)\n",
    "\n",
    "### Documents Deletion\n",
    "- ```db.collection.deleteOne({data_filter})``` - deletes one document that meets a condition\n",
    "- ```db.collection.deleteMany({data_filter})```- deletes many documents that meet a condition\n",
    "- ```db.collection.remove({data_filter})``` - removes all documents that meet the condition\n",
    "- ```db.collection.remove({data_filter}, {justOne:true})``` - removes only one document from the match\n",
    "\n",
    "### Documents Replacement\n",
    "- ```db.collection.replaceOne({data_filter}, {new fileds})``` - replace documents that meet the condition with new ones\n",
    "\n",
    "\n",
    "### Data Querying\n",
    "- ```db.collection.find({})``` - returns all documents from a collection (preferable)\n",
    "- ```db.getCollection('collection_name').find()``` - queries the data (not preferable)\n",
    "- ```db.col_name.find({}).pretty()``` - returns all documents from a collection in a pretty format\n",
    "\n",
    "\n",
    "### Filtering Documents\n",
    "- ```db.collection.find({filed: value})``` - returns a document that meets the condition\n",
    "- ```db.collection.find({'field_name.field': value})``` - condition for a field object\n",
    "- ```db.collection.find({$or: [{cond_1}, {cond_2}, ... {cond_n}]})``` - using ```OR``` operator\n",
    "- ```db.collection.find({field_name: {$gt: value})``` - using ```$gt```\n",
    "\n",
    "\n",
    "**Rows Filtering**\n",
    "To specify what fields/columns must be returned by a query use the following syntax:\n",
    "- ```db.collection.find({}, {field_name: 1 or 0})``` - 1 includes a field, 0 excludes a field\n",
    "\n",
    "### Sorting\n",
    "- ```db.collection.find().sort({field_name: -1/+1})``` - returns a sorted result\n",
    "### Count\n",
    "- ```db.collection.find().count()``` - counts documents\n",
    "### Limit\n",
    "- ```db.collection.find().limit()``` - limits the result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
