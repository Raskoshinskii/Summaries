Machine Learning
----------------

* Какой Bias и Variance у модели выдающей константное значение
	- Высокий Bias и низкий Variance


* Что происходит с Bias и Variance если когда мы увеличиваем глубину дерева в дереве решений?
	- Bias снижается, а Variance увеличивается


* Что происходит с Bias и Variance если мы добавляем нового дерева в ансабль в градиентном бустинге?
	- Bias снижается, Variance немного увеличивается


* Что такео Validation and Learning Curves? В чем разница?
	- Validation Curve обычно используется для проверки качетва моедли на train и validation при разных значениях гиперпараметра.
	Необходимо найти такую точку на графике, где качество на validation максимально. Если есть большая разница в качестве между train и test
	при определенном параметре, то это переобучение.
	- Learning Curve используется для проверки достаточности данных для обучения модели, позволяет ответить на вопрос 
	"Улучшиться ли качество модели если я доьавлю больше данных", также глядя на данный графи можно определить какой Bias/Variance имеет модель


* В чем основное достоинство Кросс Валидации?
	- Это связоно с оценкой гиперпараметров моделей. После обучения модели с параметрами по умолчанию мы бы дальше хотели улучшить 
	качество. Однако если дальше продолжать находить оптимальные параметры минимизирую ошибку на тесте мы начнем очень быстро переобучаться.
	Поэтому мы обычно разбиваем выборку на train, validation и test. Если данных очень много и классы сбалансированы, можно сделать разбиение 
	один раз. В противном случае лучше использовать Cross Validation которая каждый раз создает новый train и validation set случайно перемешивая данные
	(если нет временной зависимости). Это позволяет сделать оценку качества более надежной и достоверной.


* В чем основнной недостаток LeveOneOut (Cross-Validation)?
	- Очень долго считать, если у нас 100k наблюдений, то нужно обучить модель 100к раз (так как каждый объект должен поучаствовать в test)

 
* У тебя есть данные о пациентах, один пациент может иметь несколько наблюдений. Как грамотно произвести валидацию модели в этом случае?
	- Такие данные точно нельзя просто разделить используя train/test split. При использовании train/test split мы должны убедиться, что наблюдения
	пациента находятсся тольков train или test, иначе мы получаем Data Leak. Это также относится и кросс-валидации, в этом случае лучше использовать 
	GroupKFold или StratifiedGroupKFold, она гарантирует, что группы в train/test не будут пересекаться.


* В каких случая данные лучше отмасшьабировать, используя MinMaxScaler или MaxAbsScaler?
	- Данные методы хороши для фич, имеющих мальнькое std. MaxAbsScaler обычно используют если нужно отмасштабировать разреженные данные


* Что такое Latency Prediction / Model Through
	- Latency это сколько времени модели нужно чтобы сделать одно предсказание, пропускная способность это 
	сколько наблюдений модель может обработать за определенное время, например сек. Основные факторы которые влияют на эти параметры:
		Число признаков, тип данных и их разреженность, сложность модели. Например, при разреженности данных в 90% лучше использовать
		разреженные структуры данных (CSR, CSC) матрицы.


* Что такое Bulk Prediction и Atomic?
	- Bulk (батч) - предсказание по батчу, Аtomic - отдельно для каждого объекта. В Sklearn Bulk более эффективен, 
	так как использует векторные операции (Bulk может превосходить Atomic предсказания на несколько порядков). Для еще более 
	быстрого предсказания можно использовать параметр конфигурации SKLEARN_ASSUME_FINITE, затем импортировать sklearn. Это позволит 
	не проверять значения на пропуски и улучшить скорость.


* Способны ли линейные модели "выучить" временные зависимости от таргета (например спрос)?
	- Нет, так как они не моелируют нелинейные зависимости. Такие признаки необходимо преобразовать, например, можно использовать
	тригонометрические трансформации: cos/sin или spline. Sin и Cos должны использоваться вместе, чтобы смоделировать цикличность


* В чем проблема использования OHE для признаков времени (минуты, часы)?
	* Гранулярность времени может стать проблемой. Если мы будем использовать минуты или секунды, то число наблюдений в день будет очень большим.
	Следовательно, мы получим очень много категорий, которые будут очень разреженны и могу привести к переобучению. Также, используя OHE, мы теряем 
	временные зависимости (например, вечером спрос выше, чем утром и.т.д)


* Если сравнивать бэггинг и бустинг, то в каком из них можно достичь более значимых выгод от параллелизации?
	- При построении леса, используя бэггинг. Каждое дерево можно строить на отдельном CPU


* Предположим, что мы обучили алгоритм Random Forest и Gradient Boosted Decision Trees. В какой модели базовые решающие деревья будут иметь большую глубину?
	- В Random Forest дерева обычно строятся, используя максимальную глубину, а в бустинге деревья обычно слабые и небольшой глубины.


* Предположим, что мы обучили модель бинарной классификации, у которой AUС-ROC на тестовой выборке 0.82. Что произойдет с метрикой AUC-ROC, если мы возведём все скоры модели в третью степень? Инвариантен ли ROC-AUC к операциями умножения, деления или возведения в степень?
	- Возведение скоров модели в третью степень не повлияет на AUC-ROC как таковой, поскольку это изменение будет применено как ко всем объектам классификации, и отношения между объектами останутся прежними. Поэтому, если исходная модель имела AUC-ROC 0.82, то AUC-ROC после возведения всех скоров в третью степень также останется примерно на том же уровне. Важно чтобы отношения между объеками не изменялось!


* Можно ли градиентным спуском в задаче классификации оптимизировать метрику Accuracy?
	- Функция Accuracy является недифференцируемой, следовательно мы не модем применить градиентные методы.


* Предположим, что мы обучили модель бинарной классификации. Какие ошибки хуже?  
	- Зависит от задачи, мы сами должны определить какие ошибки для нас критичнее (I-го или II-го рода)


* Почему градиентный бустинг градиентный?
	Это связано с лосом который необходимо оптимизировать для нового алгоритма. Самый первый (базовый алгоритм в композиции) обычно простой
	и предсказывает с ошибками. Второму алгоритму в композиции необходимо минимизировать данную ошибку (отклонения/свдиги). Поэтому новый алгоритм
	в композиции обучаем на векторе сдвигов. Мы хотим найти такие сдвиги, которые позволят минимизировать ошибку текущей композиции. Получаем лосс, миниизация которого эквивалента антиградиенту функции потерь.


* Что такое экстраполяция?
	- Процесс предсказания значений за пределами диапазона обучающих данных, то есть в области, которая не была представлена в обучающей выборке.


* Какие параметры регуляризации в градиентном бустинге есть / Как можно регулязовать градиентный бустинг?
	- Основная идея регуляризации - увеличение bias и снижение variance. Основные гиперпараметры алгоритма которые могут влиять на это:
		* max_dept: чем глубже, тем боллее сложные зависимости можем восстанавливать.
		* min_samples_leaf: чем больше объектов в листе, тем проще модель
		* min_samples_split: чем меньше объектов используем для разделения, тем больше риск переобучения
		* learning_rate: скорость оптимизации
		* n_estimators: чем больше деревьем, тем больше риск переобучения 
		* max_features: ограничение максимального числа признаков для рассмотрения при разбиении
		* max_leaf_nodes: ограничение максимального числа листьев у узла (контроль сложности)


* В чем различие между LightGBM, XGBoost и CatBoost?
	- LightGBM (основная особенность - быстрый)
		- Гистограммный способ хранения данных: 
			Не использует пошаговый перебор значений признака, а использует гистограмму распределения признака
			для приближенного вычисления градиента и выборе оптимального информативного разбиения. 
		- Leaf-Wise Разбиение
			Каждый узел выбирает такое разбиение которое максимально уменьшит функцию потерь. Обычно приводит к более глубоким деревьям.
		- Categorical Feature Support
			Нет необходимости кодировать категориальные фичи.
		- Multithreading
			Возможность параллельно обучать модель на разных ядрах
		- Missing Values Handling
			Нет необходимости заполнять пропуски

	- CatBoost (основная особенность - хорошая работа с категориальными признаками)
		- Special Categorical Encoding
			Специальные методы кодирования категориальных признаков.
		- Multithreading, Missing Values Handling, 

	- XGBoost (Стандартный градиентный бустинг)
		- Missing Values Handling
			Нет необходимости заполнять пропуски
		- Categorical Feature Support
			Нет необходимости кодировать категориальные фичи.
		- Multithreading
			Возможность параллельно обучать модель на разных ядрах


* Методы ансамблирования моделей
	- Ансамбли могут улучшить стабильность и точность модели, а также снизить риск переобучения. Самые популярные методы:
		* Random Forest
		* Gradient Boosting
		* AdaBoost - Адаптивный бустинг. В каждой итерации уделяет больше внимания объектам, которые были неправильно классифицированы на предыдущих итерациях. Веса объектов регулируются, чтобы сделать более сложные для классификации объекты более важными.
		* Stacking - определяем модели которые совершают предсказания таргета (базовые). Вектор предсказаний одной модели - признак для финальной метамодели.
		Финальная метамодель обучается на признаках/прогнозах базовых моделей и совершает финальное предсказание.
		* Blending - предполагает разделение train на две части: одну часть используют для обучения базовых моделей, а другую - для оценки их производительности и создания мета-модели. Прогнозы базовых моделей на валидационном наборе данных становятся признаками для мета-модели. Мета-модель обучается на валидационных данных для создания итоговых предсказаний. Мета-модель оценивается на отложенном тестовом наборе данных, чтобы оценить качество и обобщающую способность ансамбля.


* Как дерево решений определяет Threshold для тестирования качества разбиения?
	- Классификация (непрерывные признаки)
		- Для непрерывных признаков оно ранжирует каждый из признаков в порядке возрастания и смотрит на значения где происходит переход
		с одного класса на другой. Так происходит для каждого признака (если n числовых признаков, то получаем n*n парогов для перебора)
		Далее, используя критерий информативности, определяем лучший парог, обеспичивающий наибольший прирост информации.
	- Классификация (категориальные признаки)
		- Перебирает все категории признака и определяет наилучшую категорию для разбиения (проверить!)

	- Регрессия?
		- ....


* В чем отличие SGDRegressor() от LinearRegression() in Sklearn?
	- LinearRegression() реализует обычный методнаименьших квадратов (OLS) используя аналитическое решение (Матричное Уровнение)
	Следовательно, при оптимиазции используются все данные. Это может быть проблемой на больших датасетах.
	- SGDRegressor() исползует Stochastic Gradient Descent -> не использует всю выборку, осуществляет оптимизацию по каждому наблюдению
	из обучающей выборки. Более эффективен на больших наборах данных. Однако, данный алгоритм более увствителен к выбросам, чем
	LinearRegression() -> необходим качественный preprocessing.


* Когда, почему и как нужно использовать Hashing категориальных признаков? Хорошо или плохо влияют коллизи на качество модели?
	- Это необходимо когда данные очень изменчивы в PROD среде. Например, очень часто появляются все новые и новые категории.
	В таком случае обновлять модель каждый раз -> не очень хорошая идея + необходимо обновлять и Encoder! Также, если категорий много,
	то Encoder вынужден хранить словарь категорий, что может занимат много места. В таких случаях, использование хешей позволяет
	более эффективно решать поставленную задачу. Рекомендуется хешировать не просто название категорий, а хешировать вот так:
	`hash('feature_name'+'value')` -> `hash(job=DS)`, `hash(area=stuttgart)`.
	- Как ни странно, но коллизии положително влияют на модель в таких случаях. Так как коллизии происходят редко и играют роль регуляризации модели.
	

* В чем преимущество и недостатки обучения модели на всех данных?
	- Явным преимуществом является больший объем данных для обучения. Однако, я бы ответил на следующий вопрос "Улучшит ли качество модели больше данных?"
	Для этого можно построить кривые обучения и посмотреть как изменяется качество модели в зависимости от числа наблюдений в train. Если на текущем размере
	разрыв между кривыми большой, то имеет смысл обучить модель на всех данных. Однако, стоит учитывать, что в этом случае мы не сможем провалидировать 
	модель на test, поэтому необходимо быть уверенным, что качество будет чуть лучше текущего. Для этого мы можем сравнить распределения фичей на 
	train и test. Данные распределения не должны отличаться. Если есть сильные различия, то мы не сможем быть однозначно уверенны, что качество модели
	не ухудшилось, и параметры, определенные ранее, все еще хороши. 


* Назови преимущества и недостатки Блендинга
	Преимущества блендинга:
		- проще стэкинга, меньшая вычислительная сложность
		- защищен от утечки информации в отличие от стэкинга (причина в out-of-fold)
		- вам не нужно делиться seed от stratified folds с вашими напарниками.
	Недостатки:
		- базовые алгоритмы и мета-алгоритм используют не всю обучающую выборку;
		- можно переобучиться на hold-out выборке;
		- out-of-fold более стабилен нежели использование просто hold-out выборки.

	Больше здесь: https://github.com/Yorko/mlcourse.ai/blob/main/jupyter_russian/tutorials/tutorial_ensemble_methods_qovaxx.ipynb


* Представим, что у нас есть train в котором нет отрицательных значений (предсказываем цены на товары). Явно товары не могут стоить -10 руб.
Может ли градиентный бустинг дать отрицательный прогноз? А линейная регрессия?
	- Нет ничего, чтобы ограничивало давать предсказания для градиентного бустинга вне диапазона тренировочных меток.
	Лосс может быть разный, на каком-то из объектов модель может очень сильно ошибиться. Следовательно, итоговое предсказание может стать отрицательным.
	- Линейная регрессия также может предсказать отрицательные значения. Модель способна к экстраполяции и имеет тренд который может выходить за область 
	положительных значений.


* Представим, что мы обучали градиентный бустинг к предсказанию цены товара на товарах со средней ценой. Сможет ли данный алгоритм верно предсказать 
очень дорогие или очень дешевые товары?
	- Градиентный бустинг в целом не способен экстраполировать, поэтому на таком объекте мы скорее всего будем ожидать большую ошибку.
	Однако, мы обычно имеем композицию слабых деревьев, поэтому есть вероятность, что случайно, ошибка может быть чуть ниже, чем мы ожидаем.


* Представим, что у нас есть 2 алгоритма: LogReg и RandomForest. Мы обучили эти алгоритмы на задачу классификации.
Имеем много данных и признаков, присутствует много шума. Получили, что качество LogReg значительно выше, чем у RandomForest.
Почему так могло произойти?
	- Каждое дерево будет обучаться на случайном подмножестве признаков, которое будет являться шумом. Лишь только в небольшом 
	числе случаев будут деревья, обученные на нешумовых признаках, но таких деревьев будет мало и в среднем большая часть деревьев 
	будет выдавать очень низкое качество - близкое к случайному угадыванию.
	- Логистическая регрессия будет учитывать все множество признаков и скорее всего сможет выделить зависимости из нешумовых признаков,
	а шумовые признаки отодвинуть (регуляризация в этом случаем будет только большим +).


* Представим, что мы обучали Линейную регрессию и KNN на одном и том же датасете. Затем в тестовой выборке появился объект, 
который никогда не встречался в обучающей выборке. Какой алгоритм лучше справится с прогнозом (ошибется меньше) и почему?
	- Алгоритм KNN справится хуже всего, так как совершенно новый объект будет находиться очень далеко в признаковом пространстве
	и сорее всего никогда не будет близким соседом (алгоритм не способен к экстраполяции). Линейная регрессия справится лучше,
	так как способна к экстраполяции (тренд).


* Что такое жадный алгоритм построения дерева?
	- Алгоритм который на каждом разбиении узла дерева находит наилучший признак осуществляющий наибольший прирост информации.
	Используется критерий информативности: Энтропия/Джини (Классификация), MSE (Регрессия) и Information Gain.
	! Данный алгоритм всегда приводит к деревьям большой глубины с низкой обобщающей способностью / переобученные 


* Может ли дерево идеально разделить объекты на train и достичь нулевой ошибки?
	- Да, однако такие деревья всегда переобученные


* В каких случаях дерево решений не сможет однозначно определить в какой лист однозначно отправить объект?
	- Когда есть дубли одного и того же объекта, но принадлежащего разным классам.


* Что если мы строим РС и имеем пользователей в train которые лайкают и нелайкаю одни и теже посты в разное время? Как можно решить данную проблему?
	- У нас будут объекты которые будут иметь 2 класса (лайк/не лайк). Алгоритм будет ошибаться на таких объектах, так как нет дополнительно признака 
	по которому можно было одназначно определить - понравится пост или нет. Нужно ввести признак времени и снова протестировать модель.


* Что значит если ROC-AUC меньше 0.5 и как нужно поступить в этом случае?
	- Это указывает на то, что классификатор выполняет хуже, чем случайное угадывание.
	Как правило, это может происходить, когда классификатор делает противоположные предсказания, и его результаты следует инвертировать.
	Решение - проверить корректность меток или инвертировать предсказания.

* Как при помщи ROC-AUC можно оценить ранжирование алгоритма?

* В чем проблема обратной связи в Рекомендательных Системах (FeedBack Loop). Как с этим можно бороться?
 - Модель будет обучаться на рекомендациях которые рекомендует сама. Это может исключить разнообразие и новизну в рекомендациях и в контенте. 
 Для борьбы с этим можно использовать - сэмплинг, Еps greedy


* Если взять среднее от 2-х моделей, выдающих качество ROC-AUC по 0.5 то улучшится ли прогноз?
	- Усреднение моделей может быть полезным при наличии нескольких моделей, каждая из которых дает приемлемое качество предсказаний. В этом случае усреднение может уменьшить дисперсию прогнозов и повысить стабильность модели. Однако если обе модели имеют качество хуже, чем случайное угадывание, усреднение не исправит эту проблему. Также можно сделать уклон на разнообразии персонализаций.


* Почему веса линейных моделей не являюется хорошей оценкой важности признаков?
	- Масштаб признака (пределы в которых он изменяется) влияет на его коэффицент. Рассмотрим пример, мы обучили линейную регрессию и имеем пизнак - возраст дома в годах. Если измеить масштаб признака, например трансформировать в минуты или секунды, то коэффициент станет меньше. Однако, это не означает что признак стал менее важен или не важен. Также, мы можем ошибочно отобрать топ 3/5 самых важных признаков. Они могут быть важны так как просто имеют больший масштаб/магнитуду. 


* В чем проблема неотмасштабированных признаков?
	- Ложная важность признаков 
	- Более долгая сходимость
	- Неравномерная регуляризация
	- Качество предсказания хуже 
	- Почти невозможная интепретация (оценка еденичного изменеия признака)


* В чем проблема нелинейных методов понижения размерности на векторах большой размерности?
	- Вектора большой размерности зачастую очень разреженные и нелинейные методы не способны обработать
	большие размерности, так как такие методы зачастую опираются на локальные свойства.

	Решение - использовать сначала линейное понижение (PCA или SVD), а затем прогонять нелинейные алгоритмы.
	Например, использовать TruncatedSVD на 100 компонент, и затем применять t-SNE или UMAP.

	!Оригинальные t-SNE из sklearn работает плохо на больших выборках, лучше использовать MulticoreTSNE!
	(Работает значительно быстрее). Метрика для векторов из текстов обычно не Евклидова, а косинусная мера!


* Почему веса нейронной сети должны быть проинициализированы маленькими случайными значениями, а не нулем?
	- все нейроны в одном слое будут иметь одинаковые значения на выходе, что приведет к одинаковым градиентам в процессе обучения. В результате, нейроны могут остаться симметричными и не смогут извлечь полезные признаки из данных
	- Затухание градиента: Если веса инициализированы нулями, градиенты также будут нулевыми на большинстве путей обратного прохода, что может привести к затуханию градиента и замедлению обучения.
	- Случайная инициализация весов помогает избежать локальных оптимумов при обучении.


* Нужно ли исключать стоп слова для RNN и почему? Для каких моделей/случаев стоп слова важны.
	- Обычно исключение стоп слов для RNN приводит к снижению качества, так как данные стоп слова могут
	содержать полезную информацию в предложении/последовательности (указывать на определенный предмет,
	отрицание или противопоставление, ...)
	- Обычно стоп слова исключают для не RNN моделей которые используют частотные признаки (BoW, TF-IDF).




Statistics and A/B
------------------
* Как можно проверить, что стат тесту можно доверять, например, черный ящик. Нужно определить, правильно он работает или нет
	- Можно провести АА тест и убедиться, что он находит различия лишь в 5% случаев.

* Когда мы не можем использовать критерий Хи-квадрат?
	- Маленькие ожидаемы частоты в таблице сопряженности. Это приводит к завышенной стат значимости и неверным выводам.
	- Независимость между группами. Если группы в А/B тесте были неверно разбиты, то получим ложные выводы
	- Не используется для непрерывной СВ (для непрерывных СВ использовать лучше t-тест)
	- Размер выборок: если одна группа значительно больше другой, то можно получить неверные выводы

* Как можно оценить распределение метрики из А/B теста? Например, замеряем Conversion Rate в 2-х группах
	- Для оценки стат значимости метрик из 2-х групп можно использовать Хи-квадрат. Однако, мы не всегда можем его использовать,
	Если использовать Хи-квадрат не можем, то мы можем обратиться к использованию Бутстрепа. Создаем N - бутстрапированных выборок сравниваемых метрик.
	Получим распределение CTR в сравниваемых группах и дальше можем сравнивать средние между собой, используя например t-test.
	! Однако, здесь мы должны учесть ограничения t-test
		- Самый важный момент - нормальность сравниваемых распределений. Однако, t-test можно использовать на распределениях, отличающиеся от нормального.
		Можем сравнить, используя Q-Q-Plot и Шапиро-Вилка тест для проверки на нормальность. Если видим, что распределение ненормально, использовать непараметрические критерии - непараметрический критерий Манна-Уитни (U-test)(Перестановочные Критреии и Критерии Знаков).
		Далее мы можем определить, есть ли различия. Если есть, то на сколько группы различны (эффект).


* Как будет распределена некая бутстрапированная метрика из группы и почему?
	- Центральная Предельная Теорема.  


* Представим, что мы проводим А/B тест, сравнивыемы гурппы находятся в разных гео регионах. 
Как правильно выбрать контрольную гурппу пользователей в таком случае?
	- Switch Back тесты: замеряем метрику в регионе А и B, затем то, что показывали в А, показываем в B
	а то что показывали в B, показываем в А.


* Как можно оценить тестовую группу без контроля?
	- поискать в интернете


* Почему KDE (Kernel Density Estimation) лучше чем гистограмма?
	- KDE обеспечивает более гладкую кривую, описывающую распределение данных.
	Она не имеет bias к чилу выбранных "бинов" -> более точное распределение.


* Почему иногда BoxPlot не имеет верхний или нижний ус?
	Данная ситуация может произойти в нескольких случаях:
	1) Нет значений попадающих в интервал усов:
		Например, у нас может быть много нулевых значений -> нет нижнего уса.
		Чтобы исправить это, можно исключить нулевые значения и построить boxplot снова.
	2) Слишком мало данных:
		В таком случае BoxPlot покажет только доступные данные
	3) Все сзначения могут попадать в интевал (Q1-Q3)
	






Python / Spark / Data Structures
--------------------------------
* Неизменяемы и изменяемы СД в Python. В чем основная суть изменяемых и неизменяемых СД?
	- Mutable (Изменяемые): List, Set, Dict
	- Immutable (Неизменяемые): Str, Int, Tuple, Frozenset
	Неизменяемые типы даннных всегда переиспользуют созданные объекты!

* В чем отличие между @staticmethod и @classmethod?
	- Оба методы не имеют доступа к атрибутам и методам объекта класса и не принимают объект в аргументах
	- @staticmethod 
		- Можно вызвать на классе без создания объекта (бычно его вызывают через имя класса): MyClass.static_method(x, y)
		- Такие методы не зависят от состояния объекта класса. 
	- @classmethod
		- Имеет доступ к методам и атрибутам класса

* Что такое декораторы в Python? Что они позволяют сделать? Что они возвращают?
	- Позволяют расширят функционал любой функции. Декоратор является оберткой над функцией,
	принимает функцию как аргумент и возвращает функцию



* Что такое driver и worker в Spark? Отличие между ними?


* Почему поиск в списке медленее чем во множестве?
	- Множества обычно используют СД - хеш таблица. Поэтому при поиске элемента во множестве необходимо определить его хеш и найти.
	Операция выполняется за констатное время O(1)
	- Лист использует СД - динамический массив. При поиске необходимо поэлементное сравнение.
	Операция выполняется за линейное время O(n) 
	
* Что такое BroadCasting в Spark?
	Это механизм оптимизации, который позволяет эффективно передавать (распространять) небольшие данные между узлами кластера во время выполнения операций обработки данных. Это позволяет уменьшить объем данных, передаваемых по сети, и улучшает производительность выполнения операций, так как данные, которые могут быть эффективно переданы через Broadcasting, не нужно отправлять на каждый узел кластера.

	Используется например, при выполнении операций соединения (join) между DataFrame или при выполнении операций фильтрации (filter) на больших наборах данных. В этих случаях, если одна из сторон (например, маленький DataFrame) может быть передана весьма эффективно, то она будет "забродкастена" на все узлы кластера, что позволит выполнять операции быстрее.