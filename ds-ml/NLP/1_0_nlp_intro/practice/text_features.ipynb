{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Features\n",
    "Any text for machine learning model must be preprocessed and encoded into numbers. Theare are many different techniques that allow to implement it:\n",
    "- Bag of Words (TF-IDF and N-Grams)\n",
    "- Word Embeddings \n",
    "- Manually Defined Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vlad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import Word, TextBlob\n",
    "import re \n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from scipy.sparse import csr_matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Manual Feature Engineering**\n",
    "\n",
    "Usually, specific domain leads to specific information, hidden inside of your data. We need to extract it, as much as possible. For example, for sentiment analysis task we may have the following texts:\n",
    "- `\"Average film, however, starring Matt Damon, 8/10\"` -> 8/10 means positive sentiment\n",
    "- `\"2/10, there is nothing to add\"` -> 2/10 means negative sentiment\n",
    "\n",
    "**Token Based Features**\n",
    "- smiles positive/negative\n",
    "- numbers that might be related to rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rate(text: str):\n",
    "    rating_candidates = re.findall(r'(\\d{1,3}[\\\\|/]{1}\\d{1,2})', text)\n",
    "    rates = []\n",
    "    for candidate in rating_candidates:\n",
    "        try:\n",
    "            rates.append(eval(candidate))\n",
    "        except SyntaxError:\n",
    "            pass\n",
    "        except ZeroDivisionError:\n",
    "            return 0\n",
    "    return np.mean(rates) if rates else -1\n",
    "\n",
    "def get_positive_smiles():\n",
    "    positive_smiles = set([\n",
    "    \":‑)\",\":)\",\":-]\",\":]\",\":-3\",\":3\",\":->\",\":>\",\"8-)\",\"8)\",\":-}\",\":}\",\":o)\",\":c)\",\":^)\",\"=]\",\"=)\",\":‑D\",\":D\",\"8‑D\",\"8D\",\n",
    "    \"x‑D\",\"xD\",\"X‑D\",\"XD\",\"=D\",\"=3\",\"B^D\",\":-))\",\";‑)\",\";)\",\"*-)\",\"*)\",\";‑]\",\";]\",\";^)\",\":‑,\",\";D\",\":‑P\",\":P\",\"X‑P\",\"XP\",\n",
    "    \"x‑p\",\"xp\",\":‑p\",\":p\",\":‑Þ\",\":Þ\",\":‑þ\",\":þ\",\":‑b\",\":b\",\"d:\",\"=p\",\">:P\", \":'‑)\", \":')\",  \":-*\", \":*\", \":×\"\n",
    "    ])\n",
    "    return positive_smiles\n",
    "\n",
    "def get_negative_smiles():\n",
    "    negative_smiles = set([\n",
    "    \":‑(\",\":(\",\":‑c\",\":c\",\":‑<\",\":<\",\":‑[\",\":[\",\":-||\",\">:[\",\":{\",\":@\",\">:(\",\"D‑':\",\"D:<\",\"D:\",\"D8\",\"D;\",\"D=\",\"DX\",\":‑/\",\n",
    "    \":/\",\":‑.\",'>:\\\\', \">:/\", \":\\\\\", \"=/\" ,\"=\\\\\", \":L\", \"=L\",\":S\",\":‑|\",\":|\",\"|‑O\",\"<:‑|\"\n",
    "    ])\n",
    "    return negative_smiles\n",
    "\n",
    "\n",
    "def get_token_features(text, return_sparce=False):\n",
    "    features_df = pd.DataFrame()\n",
    "    positive_smiles = get_positive_smiles()\n",
    "    negative_smiles = get_negative_smiles()\n",
    "\n",
    "    features_df['rating'] = text.apply(get_rate).fillna(-1)\n",
    "    features_df['positive_smiles'] = text.apply(lambda s: len([x for x in s.split() if x in positive_smiles]))\n",
    "    features_df['negative_smiles'] = text.apply(lambda s: len([x for x in s.split() if x in negative_smiles]))\n",
    "\n",
    "    if return_sparce:\n",
    "        return csr_matrix(features_df.values)\n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sentence-based Features**\n",
    "- Count Features\n",
    "    - sentence len\n",
    "    - exclamation mark, question mark, ...\n",
    "    - uppercase word count\n",
    "\n",
    "- Contrast\n",
    "    - words like \"instead\", \"on the contrary\", ...\n",
    "\n",
    "- First last sentence comparison:\n",
    "    - polarity, subjectivity, purity of first/last sentence[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contras_words():\n",
    "    contrast_conj = set([\n",
    "        'alternatively','anyway','but','by contrast','differ from','elsewhere','even so','however','in contrast','in fact',\n",
    "        'in other respects','in spite of','in that respect','instead','nevertheless','on the contrary','on the other hand',\n",
    "        'rather','though','whereas','yet'\n",
    "    ])\n",
    "    return contrast_conj\n",
    "\n",
    "# to get review \"purity\" ~ shows same sentiment over review (~1) or changing sentiment (~0)\n",
    "def get_purity(text: str):\n",
    "    \"\"\"\n",
    "    Obtain polarities across the sentences.\n",
    "    shows same sentiment over review (~1) or changing sentiment (~0)\n",
    "    \"\"\"\n",
    "    polarities = np.array([TextBlob(x).sentiment.polarity for x in text])\n",
    "    return polarities.sum() / np.abs(polarities).sum()\n",
    "\n",
    "\n",
    "def get_text_features(text, return_sparce=False):\n",
    "    features_df = pd.DataFrame()\n",
    "    uppercase_pattern = re.compile(r'(\\b[0-9]*[A-Z]+[0-9]*[A-Z]+[0-9]*\\b)')\n",
    "    sentence_splitter = re.compile('(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<![A-Z]\\.)(?<=\\!|\\?|\\.)\\s')\n",
    "    contrast_words = get_contras_words()\n",
    "\n",
    "    features_df['sentences'] = text.apply(lambda s: re.split(sentence_splitter, s))\n",
    "    features_df['sentence_cnt'] = text.apply(len) \n",
    "    features_df['exclamation_cnt'] = text.str.count('\\!') \n",
    "    features_df['question_cnt'] = text.str.count('\\?')\n",
    "    features_df['upper_word_cnt'] = text.apply(lambda s: len(re.findall(uppercase_pattern, s)))\n",
    "    features_df['contrast_conj_cnt'] = text.apply(lambda s: len([c for c in contrast_words if c in s]))\n",
    "\n",
    "    features_df['polarity_1st_sent'] = features_df['sentences'].apply(lambda s: TextBlob(s[0]).sentiment.polarity)\n",
    "    features_df['polarity_last_sent'] = features_df['sentences'].apply(lambda s: TextBlob(s[-1]).sentiment.polarity)\n",
    "    features_df['subjectivity_1st_sent'] = features_df['sentences'].apply(lambda s: TextBlob(s[0]).sentiment.subjectivity)\n",
    "    features_df['subjectivity_last_sent'] = features_df['sentences'].apply(lambda s: TextBlob(s[-1]).sentiment.subjectivity)\n",
    "    features_df['polarity'] = text.apply(lambda s: TextBlob(s[-1]).sentiment.polarity)\n",
    "    features_df['purity'] = features_df['sentences'].apply(get_purity).fillna(0)\n",
    "\n",
    "    if return_sparce:\n",
    "        return csr_matrix(features_df[features_df.columns[1:]].values)\n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>positive_smiles</th>\n",
       "      <th>negative_smiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating  positive_smiles  negative_smiles\n",
       "0     0.3                0                1\n",
       "1    -1.0                0                0\n",
       "2    -1.0                1                0\n",
       "3     0.7                0                0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's test custom features:\n",
    "reviews = pd.Series([\n",
    "    \"Waste of time :( 2/10 for the plot and 4/10 for acting!\",\n",
    "    'Awful film! Nobody can like it',\n",
    "    'Wow! Am I impressed?? TOTALLY :D',\n",
    "    '7/10'\n",
    "])\n",
    "\n",
    "# token-based\n",
    "token_features = get_token_features(reviews)\n",
    "token_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>sentence_cnt</th>\n",
       "      <th>exclamation_cnt</th>\n",
       "      <th>question_cnt</th>\n",
       "      <th>upper_word_cnt</th>\n",
       "      <th>contrast_conj_cnt</th>\n",
       "      <th>polarity_1st_sent</th>\n",
       "      <th>polarity_last_sent</th>\n",
       "      <th>subjectivity_1st_sent</th>\n",
       "      <th>subjectivity_last_sent</th>\n",
       "      <th>polarity</th>\n",
       "      <th>purity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Waste of time :( 2/10 for the plot and 4/10 f...</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.316667</td>\n",
       "      <td>-0.316667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Awful film!, Nobody can like it]</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Wow!, Am I impressed??, TOTALLY :D]</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[7/10]</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences  sentence_cnt  \\\n",
       "0  [Waste of time :( 2/10 for the plot and 4/10 f...            55   \n",
       "1                  [Awful film!, Nobody can like it]            30   \n",
       "2               [Wow!, Am I impressed??, TOTALLY :D]            32   \n",
       "3                                             [7/10]             4   \n",
       "\n",
       "   exclamation_cnt  question_cnt  upper_word_cnt  contrast_conj_cnt  \\\n",
       "0                1             0               0                  0   \n",
       "1                1             0               0                  0   \n",
       "2                1             2               1                  0   \n",
       "3                0             0               0                  0   \n",
       "\n",
       "   polarity_1st_sent  polarity_last_sent  subjectivity_1st_sent  \\\n",
       "0          -0.316667           -0.316667               0.333333   \n",
       "1          -1.000000            0.000000               1.000000   \n",
       "2           0.125000            0.500000               1.000000   \n",
       "3           0.000000            0.000000               0.000000   \n",
       "\n",
       "   subjectivity_last_sent  polarity  purity  \n",
       "0                0.333333       0.0    -1.0  \n",
       "1                0.000000       0.0    -1.0  \n",
       "2                0.875000       0.0     1.0  \n",
       "3                0.000000       0.0     0.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text-based\n",
    "sentence_features = get_text_features(reviews)\n",
    "sentence_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FeatureUnion. Glue Different Feature Bricks\n",
    "Sometimes, we need to \"glue\" different feature \"bricks\" into one feature matrix *X*. For example, we may want to combine BoW features and manually generated features. The best and easiest way to do it, use `sklear.FeatureUnion`\n",
    "\n",
    "However, all that feature blocks must be wrapped with a class that implements `.fit()` and `.transform()` methods. This can be achieved in several ways:\n",
    "- deriving a class from `BaseTransformer`\n",
    "- writing a custom function and passing it into `FunctionTransformer`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider simple examle\n",
    "def get_features_a(X):\n",
    "    return X\n",
    "\n",
    "def get_features_b(X):\n",
    "    return X**2\n",
    "\n",
    "features1 = FunctionTransformer(\n",
    "    func=get_features_a,\n",
    "    validate=False, # to silence many warnings\n",
    "    accept_sparse=True # to use convenient sparse representations\n",
    ")\n",
    "\n",
    "features2 = FunctionTransformer(\n",
    "    func=get_features_b,\n",
    "    validate=False, # to silence many warnings\n",
    "    accept_sparse=True # to use convenient sparse representations\n",
    ")\n",
    "\n",
    "features = FeatureUnion([\n",
    "    ('f1', features1),\n",
    "    ('f2', features2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 0, 1]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([\n",
    "    [1, 0, 0],\n",
    "    [0, 1, 0],\n",
    "    [0, 0, 1]\n",
    "])\n",
    "\n",
    "features.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
